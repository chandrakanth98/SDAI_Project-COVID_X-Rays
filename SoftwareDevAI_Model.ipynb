{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGZM02iBexyY",
    "outputId": "1a1f27f8-f443-453e-a114-1a00cacf095c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mh48tFhBfHvg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, concatenate, Conv2DTranspose, BatchNormalization, MaxPooling2D, Dropout, ReLU, Reshape, \\\n",
    " Flatten, Dense\n",
    "from tensorflow.keras import initializers\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import shutil\n",
    "from skimage.filters import sobel\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bwp4byk-q6W-"
   },
   "outputs": [],
   "source": [
    "def pure_pil_alpha_to_color_v2(image, color=(255, 255, 255)):\n",
    "    \"\"\"Alpha composite an RGBA Image with a specified color.\n",
    "\n",
    "    Simpler, faster version than the solutions above.\n",
    "\n",
    "    Source: http://stackoverflow.com/a/9459208/284318\n",
    "\n",
    "    Keyword Arguments:\n",
    "    image -- PIL RGBA Image object\n",
    "    color -- Tuple r, g, b (default 255, 255, 255)\n",
    "\n",
    "    \"\"\"\n",
    "    image.load()  # needed for split()\n",
    "    background = Image.new('RGB', image.size, color)\n",
    "    background.paste(image, mask=image.split()[3])  # 3 is the alpha channel\n",
    "    return background\n",
    "\n",
    "\n",
    "def convert(rgba):\n",
    "    rgb = pure_pil_alpha_to_color_v2(rgba)\n",
    "    return np.array(rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JDqYXXrCfZiV"
   },
   "outputs": [],
   "source": [
    "# Data Specifications\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rGU0DMUCsOic"
   },
   "outputs": [],
   "source": [
    "# Functions to calculate the recall, precision, and F1-Scores\n",
    "# Adopted from: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7cKjV-rnN-z"
   },
   "source": [
    "# Data Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rYFV2ISCnQsW"
   },
   "outputs": [],
   "source": [
    "# A Data Reader Class used in one of the experiment to read the images from folders\n",
    "\n",
    "class ImageDataset(tf.data.Dataset):\n",
    "    # This class was only used for the experiment in which we used image \n",
    "    # gradients as a part of the input images.\n",
    "\n",
    "    OUTPUT_TYPES = (tf.float32, tf.float32)\n",
    "    OUTPUT_SHAPES = ((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), ())\n",
    "\n",
    "    def _generator(use_images_paths,labels):\n",
    "        for image_path,label in zip(use_images_paths,labels):\n",
    "             \n",
    "            image = Image.open(image_path.decode())\n",
    "            \n",
    "            if np.array(image).shape[-1] == 4:\n",
    "                image = convert(image)\n",
    "            \n",
    "            image = np.array(image,dtype=np.float32)/255.\n",
    "\n",
    "            # converting the images to grayscale and extracting the gradients\n",
    "            gray = np.zeros((IMG_HEIGHT, IMG_WIDTH), dtype=np.float)\n",
    "            gray += image.mean(axis=-1)\n",
    "            gradient = sobel(gray)\n",
    "\n",
    "            yield np.stack([gray,gray,gradient],axis=-1), label\n",
    "    \n",
    "    def __new__(cls, use_images_paths,labels):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=cls.OUTPUT_TYPES,\n",
    "            output_shapes=cls.OUTPUT_SHAPES,\n",
    "            args=(use_images_paths,labels)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFZamHqlfrRr"
   },
   "source": [
    "#Data Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ykXteWU2ftyp"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    \"\"\"\n",
    "    This function is used to change the learning rate as the training progresses.\n",
    "\n",
    "    :param epoch: an int variable showing the current epoch number.\n",
    "    :return: the learning corresponding the value of the epoch\n",
    "    \"\"\"\n",
    "    if epoch < 10:\n",
    "\n",
    "        return 0.00001\n",
    "\n",
    "    else:\n",
    "\n",
    "        return 0.00001\n",
    "\n",
    "\n",
    "def configure_for_performance(ds, BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    This function prepares the dataset and builds up data pipeline.\n",
    "    Shuffling, Batching, and Prefetching is performed to enhance the training speed.\n",
    "    :param ds: the dataset, which is a tf.data.Dataset\n",
    "    :return: the modified dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # Depending on the amount of the available RAM you could use either just Batching\n",
    "    # or all of instructions mentioned below.\n",
    "\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1-5VWFkfxou"
   },
   "source": [
    "#Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-gHopI2ef4yo"
   },
   "outputs": [],
   "source": [
    "# It is a customized training loop that we used initially, however, we switched \n",
    "# to default training loop in the final experiment.\n",
    "\n",
    "class CustomFit(tf.keras.Model):\n",
    "    def train_step(self, data):\n",
    "        x, label = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self(x, training=True)\n",
    "            c = self.compiled_loss(label, logits, regularization_losses=self.losses)\n",
    "\n",
    "        training_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(c, training_vars)\n",
    "\n",
    "        # Step with optimizer\n",
    "        self.optimizer.apply_gradients(zip(gradients, training_vars))\n",
    "\n",
    "        self.compiled_metrics.update_state(label, logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6XsyDbIgIQj"
   },
   "source": [
    "#Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N73dCjyPkCjn",
    "outputId": "0cf3c7c5-1d97-406d-b547-38d921b739b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Functional)    (None, 5, 5, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              209719296 \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12291     \n",
      "=================================================================\n",
      "Total params: 248,348,451\n",
      "Trainable params: 226,529,283\n",
      "Non-trainable params: 21,819,168\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "\n",
    "# Pre-trained Backbone\n",
    "mbnet = tf.keras.applications.InceptionV3(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), include_top=False, weights='imagenet',\n",
    "    input_tensor=inputs)\n",
    "\n",
    "# Freezing the weights\n",
    "for layer in mbnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Feature Extraction\n",
    "features = mbnet(inputs)\n",
    "flat_features = tf.keras.layers.Flatten()(features)\n",
    "\n",
    "# Adding the additional 2 FC layers \n",
    "\n",
    "l1 = Dense(4096,'relu')(flat_features)\n",
    "l1 = tf.keras.layers.BatchNormalization()(l1)\n",
    "l\n",
    "1 = Dense(4096,'relu')(l1)\n",
    "l1 = tf.keras.layers.BatchNormalization()(l1)\n",
    "dp = tf.keras.layers.Dropout(0.4)(l1)\n",
    "\n",
    "output = Dense(3)(dp)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\",f1_m,precision_m, recall_m])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyMnSDE-hd6I"
   },
   "source": [
    "#Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NzwCXnb0hDs5"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# A switch between train and test phases.\n",
    "\n",
    "is_train = True\n",
    "\n",
    "# path to save the model weights and parameters\n",
    "if is_train:\n",
    "    checkpoint_path = \"drive/MyDrive/SoftwareAI/baseline_weights/InceptionV3-{epoch:04d}.ckpt\"\n",
    "else:\n",
    "    checkpoint_path = \"drive/MyDrive/SoftwareAI/baseline_weights/InceptionV3-0020.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Path to save the logs according to the time\n",
    "log_dir = \"drive/MyDrive/SoftwareAI/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Qi7Jf6shivi"
   },
   "source": [
    "#Preparing Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "2cRS9a-7Plqv",
    "outputId": "ec171443-1b0f-4a8c-84c4-b5c8de277ab7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid</td>\n",
       "      <td>drive/MyDrive/SoftwareAI/dataset2/train/covid/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid</td>\n",
       "      <td>drive/MyDrive/SoftwareAI/dataset2/train/covid/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid</td>\n",
       "      <td>drive/MyDrive/SoftwareAI/dataset2/train/covid/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid</td>\n",
       "      <td>drive/MyDrive/SoftwareAI/dataset2/train/covid/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid</td>\n",
       "      <td>drive/MyDrive/SoftwareAI/dataset2/train/covid/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>pneumonia</td>\n",
       "      <td>drive/MyDrive/SoftwareAI/dataset2/train/pneumo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755</th>\n",
       "      <td>pneumonia</td>\n",
       "      <td>drive/MyDrive/SoftwareAI/dataset2/train/pneumo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6756</th>\n",
       "      <td>pneumonia</td>\n",
       "      <td>drive/MyDrive/SoftwareAI/dataset2/train/pneumo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>pneumonia</td>\n",
       "      <td>drive/MyDrive/SoftwareAI/dataset2/train/pneumo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>pneumonia</td>\n",
       "      <td>drive/MyDrive/SoftwareAI/dataset2/train/pneumo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6759 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                                dir\n",
       "0         covid  drive/MyDrive/SoftwareAI/dataset2/train/covid/...\n",
       "1         covid  drive/MyDrive/SoftwareAI/dataset2/train/covid/...\n",
       "2         covid  drive/MyDrive/SoftwareAI/dataset2/train/covid/...\n",
       "3         covid  drive/MyDrive/SoftwareAI/dataset2/train/covid/...\n",
       "4         covid  drive/MyDrive/SoftwareAI/dataset2/train/covid/...\n",
       "...         ...                                                ...\n",
       "6754  pneumonia  drive/MyDrive/SoftwareAI/dataset2/train/pneumo...\n",
       "6755  pneumonia  drive/MyDrive/SoftwareAI/dataset2/train/pneumo...\n",
       "6756  pneumonia  drive/MyDrive/SoftwareAI/dataset2/train/pneumo...\n",
       "6757  pneumonia  drive/MyDrive/SoftwareAI/dataset2/train/pneumo...\n",
       "6758  pneumonia  drive/MyDrive/SoftwareAI/dataset2/train/pneumo...\n",
       "\n",
       "[6759 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data files from the Google Drive and creating a dataframe from names and paths\n",
    "\n",
    "data_dir = 'drive/MyDrive/SoftwareAI/dataset2/train/'\n",
    "data_dirs = []\n",
    "for sub_folder in os.listdir(data_dir):\n",
    "    for name in os.listdir(data_dir + sub_folder):\n",
    "        data_dirs.append([sub_folder, data_dir+sub_folder+'/'+name])\n",
    "\n",
    "data_frame = pd.DataFrame(data=data_dirs,columns=['label','dir'])\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRPBNUOPQptt"
   },
   "outputs": [],
   "source": [
    "# Splitting the training from testing data\n",
    "image_train,image_test,label_train,label_test = train_test_split(data_frame['dir'].values,data_frame['label'].values,stratify=data_frame['label'].values,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGpwIM55REZJ"
   },
   "outputs": [],
   "source": [
    "# Transfering the training data into separate covid, normal and pneumonia folders\n",
    "\n",
    "os.makedirs('drive/MyDrive/SoftwareAI/dataset3/train/covid',exist_ok=True)\n",
    "os.makedirs('drive/MyDrive/SoftwareAI/dataset3/train/normal',exist_ok=True)\n",
    "os.makedirs('drive/MyDrive/SoftwareAI/dataset3/train/pneumonia',exist_ok=True)\n",
    "\n",
    "for name in image_train:\n",
    "    if 'pneumonia' in name:\n",
    "        shutil.copy(name,'drive/MyDrive/SoftwareAI/dataset3/train/pneumonia')\n",
    "    if 'covid' in name:\n",
    "        shutil.copy(name,'drive/MyDrive/SoftwareAI/dataset3/train/covid')\n",
    "    if 'normal' in name:\n",
    "        shutil.copy(name,'drive/MyDrive/SoftwareAI/dataset3/train/normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsQKfzUsXq0R"
   },
   "outputs": [],
   "source": [
    "# Transfering the test data into separate covid, normal and pneumonia folders\n",
    "os.makedirs('drive/MyDrive/SoftwareAI/dataset3/test/covid',exist_ok=True)\n",
    "os.makedirs('drive/MyDrive/SoftwareAI/dataset3/test/normal',exist_ok=True)\n",
    "os.makedirs('drive/MyDrive/SoftwareAI/dataset3/test/pneumonia',exist_ok=True)\n",
    "\n",
    "for name in image_test:\n",
    "    if 'pneumonia' in name:\n",
    "        shutil.copy(name,'drive/MyDrive/SoftwareAI/dataset3/test/pneumonia')\n",
    "    if 'covid' in name:\n",
    "        shutil.copy(name,'drive/MyDrive/SoftwareAI/dataset3/test/covid')\n",
    "    if 'normal' in name:\n",
    "        shutil.copy(name,'drive/MyDrive/SoftwareAI/dataset3/test/normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zOnDhuioLB6",
    "outputId": "6971fe76-c925-4f85-ebe6-1f45639f14a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5380 images belonging to 3 classes.\n",
      "{'covid': 0, 'normal': 1, 'pneumonia': 2}\n",
      "Found 1343 images belonging to 3 classes.\n",
      "Found 179 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'drive/MyDrive/SoftwareAI/dataset2/train/'\n",
    "\n",
    "# Creating separate dataset generators upon the folders \n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, fill_mode='nearest')\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Creating the datasets for training, validation and testing\n",
    "\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    directory='drive/MyDrive/SoftwareAI/dataset3/train/',\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=10,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "test_ds = val_datagen.flow_from_directory(\n",
    "    directory='drive/MyDrive/SoftwareAI/dataset3/test/',\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=10,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "val_ds = val_datagen.flow_from_directory(\n",
    "    directory='drive/MyDrive/SoftwareAI/dataset2/val/',\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=10,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BlitcT_6hiXk",
    "outputId": "57835c9c-7db7-40e2-b145-596aef671cf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "538/538 [==============================] - 366s 640ms/step - loss: 0.2180 - accuracy: 0.9234 - f1_m: 0.8360 - precision_m: 0.7743 - recall_m: 0.9164 - val_loss: 0.2050 - val_accuracy: 0.9300 - val_f1_m: 0.8616 - val_precision_m: 0.8358 - val_recall_m: 0.8993\n",
      "\n",
      "Epoch 00008: saving model to drive/MyDrive/SoftwareAI/baseline_weights/InceptionV3-0008.ckpt\n"
     ]
    }
   ],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch')\n",
    "\n",
    "# Callback to save the logs on tensorboard\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq=200)\n",
    "\n",
    "# Callback to adjust the learning rate according to the training epoch\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# Starting the training on GPU\n",
    "with tf.device('/gpu:0'):\n",
    "    model.load_weights('drive/MyDrive/SoftwareAI/baseline_weights/InceptionV3-0007.ckpt')\n",
    "    model.fit(train_ds, epochs=20, verbose=1, validation_data=val_ds,initial_epoch=7,\n",
    "                callbacks=[cp_callback,tensorboard_callback, lr_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rS1SMeWLxVxf",
    "outputId": "ade1ce37-3502-473b-dddd-9b06fce03846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 47s 2s/step - loss: 0.3541 - accuracy: 0.8883 - f1_m: 0.8252 - precision_m: 0.8119 - recall_m: 0.8500\n",
      "135/135 [==============================] - 24s 175ms/step - loss: 0.2047 - accuracy: 0.9352 - f1_m: 0.8563 - precision_m: 0.8334 - recall_m: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20467253029346466,\n",
       " 0.9352196455001831,\n",
       " 0.8563085794448853,\n",
       " 0.8334306478500366,\n",
       " 0.8888892531394958]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the trained model\n",
    "model.load_weights('drive/MyDrive/SoftwareAI/baseline_weights/InceptionV3-0004.ckpt')\n",
    "\n",
    "# Evaluating the model on the validation and test sets according to the metrics\n",
    "model.evaluate(val_ds)\n",
    "model.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "qdmI7VXpV9sx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "qRq_aF-UP536"
   },
   "outputs": [],
   "source": [
    "def backprop_receptive_field(image_dir, image_name, weight_path, save_directory, use_trained=False,\n",
    "                             use_max_activation=False):\n",
    "    \"\"\"\n",
    "        CNN Receptive Field Computation Using Backprop with TensorFlow\n",
    "        Adopted from: https://learnopencv.com/cnn-receptive-field-computation-using-backprop-with-tensorflow/\n",
    "    :param image_dir: path to the image\n",
    "    :param image_name: name of the image\n",
    "    :param weight_path: path to saved weights\n",
    "    :param save_directory: path to saved the results\n",
    "    :param use_trained: boolean, whether to use trained model or random\n",
    "    :param use_max_activation: a parameter to whether use maximum activation score \n",
    "    \"\"\"\n",
    "\n",
    "    inputs = Input((224, 224, 3))\n",
    "\n",
    "\n",
    "    # The backbone definition\n",
    "    mbnet = tf.keras.applications.InceptionV3(input_shape=(224, 224, 3), include_top=False,\n",
    "                                              weights='imagenet',\n",
    "                                              input_tensor=inputs)\n",
    "    # freezing the backbone\n",
    "    for layer in mbnet.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    features = mbnet(inputs)\n",
    "    flat_features = tf.keras.layers.Flatten()(features)\n",
    "    l1 = Dense(4096, 'relu')(flat_features)\n",
    "    l1 = tf.keras.layers.BatchNormalization()(l1)\n",
    "    l1 = Dense(4096, 'relu')(l1)\n",
    "    l1 = tf.keras.layers.BatchNormalization()(l1)\n",
    "    dp = tf.keras.layers.Dropout(0.4)(l1)\n",
    "    output = Dense(3)(dp)\n",
    "    model = tf.keras.Model(inputs, features)\n",
    "\n",
    "    # Loading the weights\n",
    "    if use_trained:\n",
    "        model.load_weights(weight_path)\n",
    "        print('model weights loaded.')\n",
    "\n",
    "    new_image = plt.imread(image_dir)\n",
    "    if len(new_image.shape) == 4:\n",
    "        new_image = convert(image_dir)\n",
    "    elif len(new_image.shape) == 2:\n",
    "        image = plt.imread(image_dir)\n",
    "        new_image = np.zeros(list(image.shape)[:2]+[3],dtype=np.float32)\n",
    "        new_image[:, :, 0] = image\n",
    "        new_image[:, :, 1] = image\n",
    "        new_image[:, :, 2] = image\n",
    "    new_image = new_image.astype(np.uint8)\n",
    "    image = Image.fromarray(new_image).resize((224, 224))\n",
    "    image = np.array(image, dtype=np.float32) / 255.\n",
    "    image = tf.expand_dims(image, 0)\n",
    "\n",
    "    pred = model.predict(image)\n",
    "    preds = tf.transpose(pred, perm=[0, 3, 1, 2])\n",
    "    preds = tf.nn.softmax(preds, axis=1)\n",
    "    pred = tf.math.reduce_max(preds, axis=1)\n",
    "    class_idx = tf.math.argmax(preds, axis=1)\n",
    "    row_max = tf.math.reduce_max(pred, axis=1)\n",
    "    row_idx = tf.math.argmax(pred, axis=1)\n",
    "    col_idx = tf.math.argmax(row_max, axis=1)\n",
    "    predicted_class = tf.gather_nd(class_idx, (0, tf.gather_nd(row_idx, (0, col_idx[0])), col_idx[0]))\n",
    "    score_map = tf.expand_dims(preds[0, predicted_class, :, :], 0).numpy()\n",
    "\n",
    "    input = tf.ones_like(image)\n",
    "    out = model.predict(image)\n",
    "\n",
    "    receptive_field_mask = tf.Variable(tf.zeros_like(out))\n",
    "\n",
    "    if not use_max_activation:\n",
    "        receptive_field_mask[:, :, :, predicted_class].assign(score_map)\n",
    "    else:\n",
    "        scoremap_max_row_values = tf.math.reduce_max(score_map, axis=1)\n",
    "        max_row_id = tf.math.argmax(score_map, axis=1)\n",
    "        max_col_id = tf.math.argmax(scoremap_max_row_values, axis=1).numpy()[0]\n",
    "        max_row_id = max_row_id[0, max_col_id].numpy()\n",
    "        # update grad\n",
    "        receptive_field_mask = tf.tensor_scatter_nd_update(\n",
    "            receptive_field_mask,\n",
    "            [(0, max_row_id, max_col_id, 0)], [1],\n",
    "        )\n",
    "    grads = []\n",
    "    with tf.GradientTape() as tf_gradient_tape:\n",
    "\n",
    "        tf_gradient_tape.watch(input)\n",
    "        # get the predictions\n",
    "        preds = model(input)\n",
    "        # apply the mask\n",
    "        pseudo_loss = preds * receptive_field_mask\n",
    "        pseudo_loss = K.mean(pseudo_loss)\n",
    "        # get gradient\n",
    "        grad = tf_gradient_tape.gradient(pseudo_loss, input)\n",
    "        grad = tf.transpose(grad, perm=[0, 3, 1, 2])\n",
    "        grads.append(grad)\n",
    "\n",
    "    # The grads contains the heatmap that we need \n",
    "    return grads\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SoftwareDevAI-Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
